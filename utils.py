import torch  
import torch.nn as nn  
import matplotlib.pyplot as plt  
import numpy as np  
import math  

class PositionEmbeddingSine(nn.Module):  
    """  
    æ­£å¼¦ä½ç½®ç¼–ç æ¨¡å—  
    å®ç°2Dæ­£å¼¦ä½ç½®ç¼–ç ï¼Œä¸ºå›¾åƒçš„æ¯ä¸ªåƒç´ ä½ç½®ç”Ÿæˆå”¯ä¸€çš„ä½ç½®è¡¨ç¤º  
    """  
    def __init__(self, hidden_dim=256, temperature=10000, scale=None):  
        super().__init__()  
        self.hidden_dim = hidden_dim              # ä½ç½®ç¼–ç æ€»ç»´åº¦  
        self.num_pos_feats = hidden_dim // 2      # ä¸€åŠç»™xç»´åº¦ï¼Œä¸€åŠç»™yç»´åº¦  
        self.temperature = temperature            # æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶ç¼–ç é¢‘ç‡  
        self.scale = 2 * math.pi if scale is None else scale  # å½’ä¸€åŒ–å°ºåº¦ï¼Œé»˜è®¤2Ï€  
        
    def forward(self, x):  
        """  
        å‰å‘ä¼ æ’­ï¼šä¸ºè¾“å…¥ç‰¹å¾å›¾ç”Ÿæˆ2Dä½ç½®ç¼–ç   
        
        Args:  
            x: è¾“å…¥ç‰¹å¾å›¾ [batch_size, hidden_dim, H, W]  
            
        Returns:   
            pos: ä½ç½®ç¼–ç  [batch_size, hidden_dim, H, W]  
        """  
        bs, _, h, w = x.shape  
        device = x.device  
        # æ­¥éª¤1: ç”Ÿæˆä½ç½®ç´¢å¼•åæ ‡  
        y_embed = torch.arange(h, dtype=torch.float32, device=device) # y_embed: [0, 1, 2, ..., h-1] è¡¨ç¤ºæ¯ä¸€è¡Œçš„ç´¢å¼•  
        x_embed = torch.arange(w, dtype=torch.float32, device=device)  # x_embed: [0, 1, 2, ..., w-1] è¡¨ç¤ºæ¯ä¸€åˆ—çš„ç´¢å¼•      
        # æ­¥éª¤2: å½’ä¸€åŒ–ä½ç½®åæ ‡åˆ°[0, 2Ï€]èŒƒå›´  
        y_embed = y_embed / h * self.scale  # å°†åƒç´ åæ ‡ä»[0, h-1]æ˜ å°„åˆ°[0, 2Ï€]  
        x_embed = x_embed / w * self.scale  # å°†åƒç´ åæ ‡ä»[0, w-1]æ˜ å°„åˆ°[0, 2Ï€]  
        # æ­¥éª¤3: ç”Ÿæˆé¢‘ç‡åºåˆ—  
        dim_t = torch.arange(self.num_pos_feats, dtype=torch.float32, device=device) # dim_t: [0, 1, 2, ..., num_pos_feats-1]  
        dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)  # è®¡ç®—é¢‘ç‡: temperature^(2i/d) å…¶ä¸­iä¸ºç»´åº¦ç´¢å¼•  
        # æ­¥éª¤4: è®¡ç®—ä½ç½®ç¼–ç   
        pos_x = x_embed[:, None] / dim_t  # pos_x: [W, num_pos_feats] æ¯åˆ—çš„xç»´åº¦ä½ç½®ç¼–ç    
        pos_y = y_embed[:, None] / dim_t  # pos_y: [H, num_pos_feats] æ¯è¡Œçš„yç»´åº¦ä½ç½®ç¼–ç   
        # æ­¥éª¤5: åº”ç”¨æ­£å¼¦ä½™å¼¦å‡½æ•°å¹¶äº¤æ›¿æ’åˆ—  
        pos_x = torch.stack([pos_x[:, 0::2].sin(), pos_x[:, 1::2].cos()], dim=2).flatten(1)  # å¶æ•°ç´¢å¼•ç”¨sinï¼Œå¥‡æ•°ç´¢å¼•ç”¨cosï¼Œç„¶åå±•å¹³  
        pos_y = torch.stack([pos_y[:, 0::2].sin(), pos_y[:, 1::2].cos()], dim=2).flatten(1)  
        # æ­¥éª¤6: æ‰©å±•åˆ°2Dç½‘æ ¼  
        pos_y = pos_y[:, None, :].expand(-1, w, -1)  # pos_y: [H, W, num_pos_feats] å°†æ¯è¡Œçš„yç¼–ç å¤åˆ¶åˆ°æ‰€æœ‰åˆ—  
        pos_x = pos_x[None, :, :].expand(h, -1, -1)  # pos_x: [H, W, num_pos_feats] å°†æ¯åˆ—çš„xç¼–ç å¤åˆ¶åˆ°æ‰€æœ‰è¡Œ  
        # æ­¥éª¤7: æ‹¼æ¥xå’Œyç»´åº¦çš„ä½ç½®ç¼–ç   
        pos = torch.cat([pos_y, pos_x], dim=-1)  # pos: [H, W, hidden_dim] å®Œæ•´çš„2Dä½ç½®ç¼–ç   
        # æ­¥éª¤8: è°ƒæ•´ç»´åº¦é¡ºåºå¹¶æ‰©å±•batchç»´åº¦  
        pos = pos.permute(2, 0, 1).unsqueeze(0).expand(bs, -1, -1, -1)  # ä»[H, W, hidden_dim]è½¬ä¸º[hidden_dim, H, W]ï¼Œç„¶åæ‰©å±•åˆ°batch_size  
        
        return pos  


def visualize_sine_position_encoding():  
    """å¯è§†åŒ–æ­£å¼¦ä½ç½®ç¼–ç çš„å„ä¸ªæ­¥éª¤"""  
    
    # åˆ›å»ºä½ç½®ç¼–ç å™¨  
    pos_encoder = PositionEmbeddingSine(hidden_dim=128, temperature=10000)  
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥  
    h, w = 20, 20  
    x = torch.randn(1, 128, h, w)  
    
    # ç”Ÿæˆä½ç½®ç¼–ç   
    pos_encoding = pos_encoder(x)[0]  # [128, 20, 20]  
    
    # åˆ›å»ºå¤§å›¾  
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))  
    fig.suptitle('DETR Sine Position Encoding Visualization', fontsize=16, fontweight='bold')  
    
    # 1. åŸå§‹ä½ç½®åæ ‡  
    y_coords = torch.arange(h, dtype=torch.float32)  
    x_coords = torch.arange(w, dtype=torch.float32)  
    Y, X = torch.meshgrid(y_coords, x_coords, indexing='ij')  
    
    im1 = axes[0, 0].imshow(Y.numpy(), cmap='viridis', aspect='equal')  
    axes[0, 0].set_title('Step 1: Y Coordinates')  
    axes[0, 0].set_xlabel('Width')  
    axes[0, 0].set_ylabel('Height')  
    plt.colorbar(im1, ax=axes[0, 0], shrink=0.7)  
    
    im2 = axes[1, 0].imshow(X.numpy(), cmap='viridis', aspect='equal')  
    axes[1, 0].set_title('Step 1: X Coordinates')  
    axes[1, 0].set_xlabel('Width')  
    axes[1, 0].set_ylabel('Height')  
    plt.colorbar(im2, ax=axes[1, 0], shrink=0.7)  
    
    # 2. å½’ä¸€åŒ–åçš„åæ ‡  
    y_norm = y_coords / h * 2 * math.pi  
    x_norm = x_coords / w * 2 * math.pi  
    Y_norm, X_norm = torch.meshgrid(y_norm, x_norm, indexing='ij')  
    
    im3 = axes[0, 1].imshow(Y_norm.numpy(), cmap='viridis', aspect='equal')  
    axes[0, 1].set_title('Step 2: Normalized Y [0, 2Ï€]')  
    axes[0, 1].set_xlabel('Width')  
    axes[0, 1].set_ylabel('Height')  
    plt.colorbar(im3, ax=axes[0, 1], shrink=0.7)  
    
    im4 = axes[1, 1].imshow(X_norm.numpy(), cmap='viridis', aspect='equal')  
    axes[1, 1].set_title('Step 2: Normalized X [0, 2Ï€]')  
    axes[1, 1].set_xlabel('Width')  
    axes[1, 1].set_ylabel('Height')  
    plt.colorbar(im4, ax=axes[1, 1], shrink=0.7)  
    
    # 3. é¢‘ç‡å“åº”  
    num_pos_feats = 64  
    dim_t = torch.arange(num_pos_feats, dtype=torch.float32)  
    frequencies = 10000 ** (2 * (dim_t // 2) / num_pos_feats)  
    
    axes[0, 2].semilogy(frequencies.numpy())  
    axes[0, 2].set_title('Step 3: Frequency Sequence')  
    axes[0, 2].set_xlabel('Dimension Index')  
    axes[0, 2].set_ylabel('Frequency (log scale)')  
    axes[0, 2].grid(True, alpha=0.3)  
    
    # é€‰æ‹©ä¸åŒé¢‘ç‡çš„1Dç¼–ç ç¤ºä¾‹  
    mid_pos = h // 2  
    for i, freq_idx in enumerate([0, 16, 32, 48]):  
        if freq_idx < pos_encoding.shape[0]:  
            y_slice = pos_encoding[freq_idx, :, mid_pos].numpy()  
            axes[1, 2].plot(y_slice, label=f'Dim {freq_idx}', linewidth=2)  
    axes[1, 2].set_title('Step 5: Sin/Cos Encoding (Y direction)')  
    axes[1, 2].set_xlabel('Y Position')  
    axes[1, 2].set_ylabel('Encoding Value')  
    axes[1, 2].legend()  
    axes[1, 2].grid(True, alpha=0.3)  
    
    # 4. æœ€ç»ˆä½ç½®ç¼–ç çš„ä¸åŒé€šé“  
    channels_to_show = [0, 32, 64, 96]  
    for i, ch in enumerate(channels_to_show):  
        if i < 2:  # å‰ä¸¤ä¸ªæ˜¾ç¤ºåœ¨ç¬¬ä¸€è¡Œ  
            ax = axes[0, 3]  
            if i == 0:  
                im = ax.imshow(pos_encoding[ch].numpy(), cmap='RdBu_r', aspect='equal')  
                ax.set_title(f'Final Encoding - Channel {ch}')  
                plt.colorbar(im, ax=ax, shrink=0.7)  
        else:  # åä¸¤ä¸ªæ˜¾ç¤ºåœ¨ç¬¬äºŒè¡Œ  
            ax = axes[1, 3]  
            if i == 2:  
                im = ax.imshow(pos_encoding[ch].numpy(), cmap='RdBu_r', aspect='equal')  
                ax.set_title(f'Final Encoding - Channel {ch}')  
                plt.colorbar(im, ax=ax, shrink=0.7)  
    
    plt.tight_layout()  
    plt.show()  
    
    # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯  
    print("=" * 60)  
    print("Sine Position Encoding Analysis")  
    print("=" * 60)  
    print(f"Input shape: {x.shape}")  
    print(f"Output shape: {pos_encoding.shape}")  
    print(f"Hidden dim: {pos_encoder.hidden_dim}")  
    print(f"Num pos feats: {pos_encoder.num_pos_feats}")  
    print(f"Temperature: {pos_encoder.temperature}")  
    print(f"Scale: {pos_encoder.scale:.4f}")  
    print(f"Encoding range: [{pos_encoding.min():.4f}, {pos_encoding.max():.4f}]")  


def visualize_frequency_analysis():  
    """å¯è§†åŒ–ä¸åŒé¢‘ç‡çš„ç¼–ç æ•ˆæœ"""  
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))  
    fig.suptitle('Frequency Analysis of Sine Position Encoding', fontsize=16, fontweight='bold')  
    
    h, w = 30, 30  
    x = torch.randn(1, 64, h, w)  
    
    # ä¸åŒæ¸©åº¦å‚æ•°  
    temperatures = [100, 1000, 10000]  
    
    for i, temp in enumerate(temperatures):  
        pos_encoder = PositionEmbeddingSine(hidden_dim=64, temperature=temp)  
        encoding = pos_encoder(x)[0]  
        
        # é€‰æ‹©ç¬¬0ä¸ªé€šé“æ˜¾ç¤º2Dæ¨¡å¼  
        im1 = axes[0, i].imshow(encoding[0].numpy(), cmap='RdBu_r', aspect='equal')  
        axes[0, i].set_title(f'2D Pattern (temp={temp})')  
        axes[0, i].set_xlabel('Width')  
        axes[0, i].set_ylabel('Height')  
        plt.colorbar(im1, ax=axes[0, i], shrink=0.7)  
        
        # Yæ–¹å‘çš„1Dåˆ‡ç‰‡  
        mid_col = w // 2  
        y_slice = encoding[0, :, mid_col].numpy()  
        axes[1, i].plot(y_slice, linewidth=2)  
        axes[1, i].set_title(f'Y Direction Slice (temp={temp})')  
        axes[1, i].set_xlabel('Y Position')  
        axes[1, i].set_ylabel('Encoding Value')  
        axes[1, i].grid(True, alpha=0.3)  
    
    plt.tight_layout()  
    plt.show()  


def visualize_encoding_uniqueness():  
    """å¯è§†åŒ–ä½ç½®ç¼–ç çš„å”¯ä¸€æ€§"""  
    
    pos_encoder = PositionEmbeddingSine(hidden_dim=64)  
    h, w = 15, 15  
    x = torch.randn(1, 64, h, w)  
    encoding = pos_encoder(x)[0]  # [64, 15, 15]  
    
    # å°†2Dä½ç½®ç¼–ç å±•å¹³ä¸º1D  
    flat_encoding = encoding.view(64, -1).T  # [225, 64]  
    
    # è®¡ç®—ç›¸ä¼¼æ€§çŸ©é˜µ  
    similarity = torch.cosine_similarity(flat_encoding[:, None, :], flat_encoding[None, :, :], dim=2)  
    
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))  
    
    # 1. ä½ç½®ç¼–ç å¯è§†åŒ– (é€‰æ‹©å‡ ä¸ªé€šé“çš„å¹³å‡)  
    avg_encoding = encoding[:16].mean(0)  
    im1 = axes[0].imshow(avg_encoding.numpy(), cmap='RdBu_r', aspect='equal')  
    axes[0].set_title('Average Encoding (first 16 channels)')  
    axes[0].set_xlabel('Width')  
    axes[0].set_ylabel('Height')  
    plt.colorbar(im1, ax=axes[0], shrink=0.7)  
    
    # 2. ç›¸ä¼¼æ€§çŸ©é˜µ  
    im2 = axes[1].imshow(similarity.numpy(), cmap='viridis', aspect='equal')  
    axes[1].set_title('Position Similarity Matrix')  
    axes[1].set_xlabel('Position Index')  
    axes[1].set_ylabel('Position Index')  
    plt.colorbar(im2, ax=axes[1], shrink=0.7)  
    
    # 3. è·ç¦»vsç›¸ä¼¼æ€§å…³ç³»  
    # è®¡ç®—æ‰€æœ‰ä½ç½®å¯¹çš„æ¬§å‡ é‡Œå¾—è·ç¦»  
    positions = []  
    for i in range(h):  
        for j in range(w):  
            positions.append([i, j])  
    positions = torch.tensor(positions, dtype=torch.float32)  
    
    # é€‰æ‹©ä¸­å¿ƒç‚¹ä½œä¸ºå‚è€ƒ  
    center_idx = h * w // 2  
    center_pos = positions[center_idx]  
    
    # è®¡ç®—åˆ°ä¸­å¿ƒç‚¹çš„è·ç¦»  
    distances = torch.norm(positions - center_pos, dim=1)  
    similarities_to_center = similarity[center_idx, :]  
    
    axes[2].scatter(distances.numpy(), similarities_to_center.numpy(), alpha=0.6, s=30)
    axes[2].scatter(distances.numpy(), similarities_to_center.numpy(), alpha=0.6, s=30)  
    axes[2].set_title('Distance vs Similarity to Center')  
    axes[2].set_xlabel('Euclidean Distance')  
    axes[2].set_ylabel('Cosine Similarity')  
    axes[2].grid(True, alpha=0.3)  
    
    plt.tight_layout()  
    plt.show()  
    
    # ç»Ÿè®¡ä¿¡æ¯  
    print("=" * 60)  
    print("Position Encoding Uniqueness Analysis")  
    print("=" * 60)  
    print(f"Total positions: {h * w}")  
    print(f"Encoding dimension: {encoding.shape[0]}")  
    print(f"Average similarity: {similarity.mean():.4f}")  
    print(f"Min similarity: {similarity.min():.4f}")  
    print(f"Max similarity: {similarity.max():.4f}")  
    
    # æ£€æŸ¥å¯¹è§’çº¿(è‡ªç›¸ä¼¼æ€§)  
    diagonal = torch.diag(similarity)  
    print(f"Self-similarity (should be 1.0): {diagonal.mean():.4f} Â± {diagonal.std():.4f}")  


def compare_encoding_methods():  
    """æ¯”è¾ƒä¸åŒä½ç½®ç¼–ç æ–¹æ³•"""  
    
    h, w = 20, 20  
    x = torch.randn(1, 64, h, w)  
    
    # ä¸åŒçš„ç¼–ç æ–¹æ³•  
    encoders = {  
        'Sine (temp=1000)': PositionEmbeddingSine(64, temperature=1000),  
        'Sine (temp=10000)': PositionEmbeddingSine(64, temperature=10000),  
        'Sine (temp=100000)': PositionEmbeddingSine(64, temperature=100000)  
    }  
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))  
    fig.suptitle('Comparison of Different Temperature Settings', fontsize=16, fontweight='bold')  
    
    for i, (name, encoder) in enumerate(encoders.items()):  
        encoding = encoder(x)[0]  # [64, 20, 20]  
        
        # 2D visualization (channel 0)  
        im1 = axes[0, i].imshow(encoding[0].numpy(), cmap='RdBu_r', aspect='equal')  
        axes[0, i].set_title(f'{name} - Channel 0')  
        axes[0, i].set_xlabel('Width')  
        axes[0, i].set_ylabel('Height')  
        plt.colorbar(im1, ax=axes[0, i], shrink=0.7)  
        
        # 1D slice comparison  
        mid_row = h // 2  
        slice_data = encoding[0, mid_row, :].numpy()  
        axes[1, i].plot(slice_data, linewidth=2, label=name)  
        axes[1, i].set_title(f'{name} - Row {mid_row}')  
        axes[1, i].set_xlabel('Width')  
        axes[1, i].set_ylabel('Encoding Value')  
        axes[1, i].grid(True, alpha=0.3)  
    
    plt.tight_layout()  
    plt.show()  


# è¿è¡Œæ‰€æœ‰å¯è§†åŒ–  
if __name__ == "__main__":  
    print("ğŸ¨ Starting Sine Position Encoding Visualization...")  
    
    # ä¸»è¦å¯è§†åŒ– - å±•ç¤ºç¼–ç çš„å„ä¸ªæ­¥éª¤  
    visualize_sine_position_encoding()  
    
    # é¢‘ç‡åˆ†æ  
    visualize_frequency_analysis()  
    
    # å”¯ä¸€æ€§åˆ†æ  
    visualize_encoding_uniqueness()  
    
    # ä¸åŒå‚æ•°æ¯”è¾ƒ  
    compare_encoding_methods()  
    
    print("âœ… Visualization complete!")